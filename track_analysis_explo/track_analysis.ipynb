{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import get_cosine_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA LOADING\n",
    "\n",
    "In this section, I am loading my data from a custom dataset tailored for my specific use case. This dataset has been preprocessed and saved in a PyTorch tensor format, allowing for efficient loading and manipulation during model training and evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_preprocessed_dataset(pt_path='dataset_V2_extended.pt', shuffle=True, seed=42):\n",
    "\n",
    "    data = torch.load(pt_path)\n",
    "    X, y = data['X'], data['y']\n",
    "\n",
    "    assert len(X) == len(y)\n",
    "    if shuffle:\n",
    "        torch.manual_seed(seed)\n",
    "        indices = torch.randperm(len(X))\n",
    "        X, y = X[indices], y[indices]\n",
    "\n",
    "    train_size = int(0.8 * len(X))\n",
    "    X_train, y_train = X[:train_size], y[:train_size]\n",
    "    X_val, y_val = X[train_size:], y[train_size:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(X, y, batch_size=16, shuffle=True):\n",
    "    dataset = TensorDataset(X, y)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "x_train, y_train, x_val, y_val = load_preprocessed_dataset()\n",
    "train_data_loader = get_dataloader(x_train, y_train, batch_size=16, shuffle=False)\n",
    "val_data_loader = get_dataloader(x_val, y_val, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD MY NN\n",
    "\n",
    "In this section, I build my simple but efficient neural network made of 3 layers and dropout to regularize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "  def __init__(self, NB_FEATURES):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(NB_FEATURES, 128)\n",
    "    self.layer2 = nn.Linear(128, 256)\n",
    "    self.layer3 = nn.Linear(256, 128)\n",
    "    self.output = nn.Linear(128, 14)\n",
    "\n",
    "    self.act = nn.GELU()\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.act(self.layer1(x))\n",
    "    x = self.dropout(x)\n",
    "    x = self.act(self.layer2(x))\n",
    "    x = self.dropout(x)\n",
    "    x = self.act(self.layer3(x))\n",
    "    x = self.dropout(x)\n",
    "    last_hidden_states = x\n",
    "    out = self.output(x)\n",
    "\n",
    "    return out, last_hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "lossfn = nn.MSELoss()\n",
    "net = Net(NB_FEATURES=29)\n",
    "\n",
    "total_epochs = 150\n",
    "optim = torch.optim.AdamW(net.parameters(), lr=1e-3)\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optim,\n",
    "    num_warmup_steps=5,\n",
    "    num_training_steps=total_epochs,\n",
    ")\n",
    "\n",
    "epochs = []\n",
    "losses = []\n",
    "lrs = []\n",
    "best_loss = float('inf')\n",
    "best_model_path = \"best_model.pth\"\n",
    "net.train()\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    for step, (X, Y) in enumerate(train_data_loader):\n",
    "        optim.zero_grad(set_to_none=True)\n",
    "\n",
    "        out, _ = net(X)\n",
    "        loss = lossfn(out, Y)\n",
    "\n",
    "\n",
    "\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            torch.save(net.state_dict(), best_model_path)\n",
    "            print(f\"Saved new best model at epoch {epoch+1} step {step+1} with loss {best_loss:.4f}\")\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        scheduler.step()\n",
    "    losses.append(loss.item())\n",
    "    epochs.append(epoch)\n",
    "    print(f\"Epoch {epoch+1}, loss: {loss.item():.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.plot(epochs, losses)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE & PLOT RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(audio):\n",
    "    adl = AudioDataLoader()\n",
    "    adl.load_stats()\n",
    "    net.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "    raw_features = audio.extract_features()\n",
    "    X = torch.tensor(list(raw_features.values()), dtype=torch.float32)\n",
    "    y = torch.tensor(list(audio.labels.values()), dtype=torch.float32) * 10\n",
    "\n",
    "    # Normalize input\n",
    "    X = (X - adl.global_mean) / (adl.global_std + 1e-8)\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        res,_ = net(X)\n",
    "\n",
    "    y_true = y.detach().numpy()\n",
    "    y_pred = res.detach().numpy()\n",
    "    loss = nn.MSELoss()(res, y)\n",
    "    print(f\"True: {y_true}\")\n",
    "    print(f\"Pred: {y_pred}\")\n",
    "    print(f\"Loss: {loss.item()}\")\n",
    "\n",
    "    feature_names = [\n",
    "        \"loudness\", \"harshness\", \"compression\", \"clarity\", \"bass\", \"muddiness\",\n",
    "        \"noise_distortion\", \"stereo_width\", \"brightness\", \"warmth\",\n",
    "        \"presence\", \"reverb_amount\", \"balance\", \"masking\"\n",
    "    ]\n",
    "\n",
    "    x = range(len(feature_names))\n",
    "    bar_width = 0.35\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(x, y_true, width=bar_width, label='Target', alpha=0.7)\n",
    "    plt.bar([i + bar_width for i in x], y_pred, width=bar_width, label='Prediction', alpha=0.7)\n",
    "\n",
    "    plt.xticks([i + bar_width / 2 for i in x], feature_names, rotation=45)\n",
    "    plt.ylabel(\"Value (0â€“10 scale)\")\n",
    "    plt.title(\"Track Characteristics: Prediction vs Target\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"pred_vs_target_sample.png\", dpi=150)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
